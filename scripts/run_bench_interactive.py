#!/usr/bin/env python3
"""
ëŒ€í™”í˜• LLM ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ê¸°ë³¸ê°’ìœ¼ë¡œ ì—”í„°ë§Œ ì¹˜ë©´ 5ë¶„ ê³ ë¶€í•˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime

import yaml

# run_bench ëª¨ë“ˆ import
sys.path.insert(0, str(Path(__file__).parent))
from run_bench import LLMBenchmark


def print_header():
    """í—¤ë” ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸš€ LLM ë²¤ì¹˜ë§ˆí¬ ëŒ€í™”í˜• ì‹¤í–‰")
    print("="*60)
    print("\nğŸ’¡ íŒ: ì—”í„°ë§Œ ì¹˜ë©´ ê¸°ë³¸ê°’ ì‚¬ìš© (5ë¶„ ê³ ë¶€í•˜ í…ŒìŠ¤íŠ¸)\n")


def load_configs(config_dir: Path):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_dir / "targets.yaml", 'r', encoding='utf-8') as f:
        targets = yaml.safe_load(f)
    with open(config_dir / "models.yaml", 'r', encoding='utf-8') as f:
        models = yaml.safe_load(f)
    with open(config_dir / "workloads.yaml", 'r', encoding='utf-8') as f:
        workloads = yaml.safe_load(f)
    return targets, models, workloads


def select_option(prompt: str, options: list, default_index: int = 0) -> tuple:
    """ì˜µì…˜ ì„ íƒ (ê¸°ë³¸ê°’ ì§€ì›)"""
    print(f"\n{prompt}")
    for i, opt in enumerate(options):
        prefix = "â†’" if i == default_index else " "
        print(f"  {prefix} {i+1}. {opt['display']}")
    
    default_display = f"ê¸°ë³¸ê°’: {default_index + 1}"
    choice = input(f"\nì„ íƒ (1-{len(options)}) [{default_display}]: ").strip()
    
    if not choice:
        return default_index, options[default_index]
    
    try:
        idx = int(choice) - 1
        if 0 <= idx < len(options):
            return idx, options[idx]
        else:
            print(f"âš ï¸  ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©")
            return default_index, options[default_index]
    except ValueError:
        print(f"âš ï¸  ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©")
        return default_index, options[default_index]


def input_with_default(prompt: str, default: any, value_type=str) -> any:
    """ê¸°ë³¸ê°’ì´ ìˆëŠ” ì…ë ¥"""
    user_input = input(f"{prompt} [ê¸°ë³¸ê°’: {default}]: ").strip()
    if not user_input:
        return default
    try:
        return value_type(user_input)
    except:
        print(f"âš ï¸  ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©: {default}")
        return default


async def main():
    print_header()
    
    config_dir = Path("configs")
    output_dir = Path("results/raw")
    
    # ì„¤ì • ë¡œë“œ
    targets_config, models_config, workloads_config = load_configs(config_dir)
    
    # 1. ì„œë²„ ì„ íƒ
    target_options = [
        {
            'name': t['name'],
            'data': t,
            'display': f"{t['name']}: {t['description']}"
        }
        for t in targets_config['targets']
    ]
    
    # Sparkë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ (ì¸ë±ìŠ¤ ì°¾ê¸°)
    default_target_idx = next(
        (i for i, t in enumerate(target_options) if 'spark' in t['name'].lower()),
        0
    )
    
    _, selected_target = select_option(
        "ğŸ“¡ ë²¤ì¹˜ë§ˆí¬ ëŒ€ìƒ ì„œë²„ ì„ íƒ:",
        target_options,
        default_target_idx
    )
    target = selected_target['data']
    
    # 2. ëª¨ë¸ ì„ íƒ
    model_options = [
        {
            'name': m['name'],
            'data': m,
            'display': f"{m['name']}: {m['description']}"
        }
        for m in models_config['models']
    ]
    
    # qwen3-coder-30bë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
    default_model_idx = next(
        (i for i, m in enumerate(model_options) if 'qwen3-coder-30b' in m['name']),
        0
    )
    
    _, selected_model = select_option(
        "ğŸ¤– í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ:",
        model_options,
        default_model_idx
    )
    model_info = selected_model['data']
    
    # 3. ì›Œí¬ë¡œë“œ ì„ íƒ ë˜ëŠ” ì»¤ìŠ¤í…€
    print("\nâš™ï¸  ì›Œí¬ë¡œë“œ ì„¤ì •:")
    print("  â†’ 1. ê¸°ë³¸ ì„¤ì • ì‚¬ìš© (5ë¶„ ê³ ë¶€í•˜ í…ŒìŠ¤íŠ¸)")
    print("    2. ì‚¬ì „ ì •ì˜ëœ ì›Œí¬ë¡œë“œ ì„ íƒ")
    print("    3. ì»¤ìŠ¤í…€ ì„¤ì •")
    
    workload_choice = input("\nì„ íƒ (1-3) [ê¸°ë³¸ê°’: 1]: ").strip()
    
    if workload_choice == "3":
        # ì»¤ìŠ¤í…€ ì„¤ì •
        print("\nğŸ“ ì»¤ìŠ¤í…€ ì›Œí¬ë¡œë“œ ì„¤ì •:")
        duration = input_with_default("  í…ŒìŠ¤íŠ¸ ì‹œê°„ (ì´ˆ)", 300, int)
        rps = input_with_default("  ì´ˆë‹¹ ìš”ì²­ ìˆ˜ (RPS)", 20, int)
        max_tokens = input_with_default("  ìµœëŒ€ í† í° ìˆ˜", 1024, int)
        temperature = input_with_default("  Temperature", 0.7, float)
        
        prompt_types = ["short", "medium", "long"]
        print("\n  í”„ë¡¬í”„íŠ¸ ê¸¸ì´:")
        for i, pt in enumerate(prompt_types):
            prefix = "â†’" if i == 1 else " "
            print(f"    {prefix} {i+1}. {pt}")
        prompt_choice = input(f"  ì„ íƒ (1-3) [ê¸°ë³¸ê°’: 2 (medium)]: ").strip()
        
        if not prompt_choice or prompt_choice == "2":
            prompt_type = "medium"
        elif prompt_choice == "1":
            prompt_type = "short"
        elif prompt_choice == "3":
            prompt_type = "long"
        else:
            prompt_type = "medium"
        
        workload = {
            'name': 'custom',
            'description': f'ì»¤ìŠ¤í…€ ì„¤ì • ({duration}ì´ˆ, RPS:{rps})',
            'duration': duration,
            'rps': rps,
            'concurrency': min(rps * 10, 100),  # RPSì˜ 10ë°° ë˜ëŠ” ìµœëŒ€ 100
            'max_tokens': max_tokens,
            'temperature': temperature,
            'prompt_type': prompt_type
        }
        
    elif workload_choice == "2":
        # ì‚¬ì „ ì •ì˜ëœ ì›Œí¬ë¡œë“œ
        workload_options = [
            {
                'name': w['name'],
                'data': w,
                'display': f"{w['name']}: {w['description']} ({w['duration']}ì´ˆ, RPS:{w['rps']})"
            }
            for w in workloads_config['workloads']
        ]
        
        # high-loadë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
        default_workload_idx = next(
            (i for i, w in enumerate(workload_options) if 'high' in w['name']),
            1
        )
        
        _, selected_workload = select_option(
            "ì›Œí¬ë¡œë“œ ì„ íƒ:",
            workload_options,
            default_workload_idx
        )
        workload = selected_workload['data']
        
    else:
        # ê¸°ë³¸ê°’: 5ë¶„ ê³ ë¶€í•˜ í…ŒìŠ¤íŠ¸
        workload = {
            'name': 'high-load-5min',
            'description': '5ë¶„ ê³ ë¶€í•˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸',
            'duration': 300,
            'rps': 20,
            'concurrency': 50,
            'max_tokens': 1024,
            'temperature': 0.7,
            'prompt_type': 'medium'
        }
    
    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    prompts = workloads_config['prompt_templates'][workload['prompt_type']]
    
    # ì„¤ì • í™•ì¸
    print("\n" + "="*60)
    print("ğŸ“‹ ë²¤ì¹˜ë§ˆí¬ ì„¤ì • í™•ì¸")
    print("="*60)
    print(f"  ì„œë²„: {target['name']} - {target['description']}")
    print(f"  ëª¨ë¸: {model_info['full_name']}")
    print(f"  ì›Œí¬ë¡œë“œ: {workload['description']}")
    print(f"    - ì‹œê°„: {workload['duration']}ì´ˆ ({workload['duration']//60}ë¶„)")
    print(f"    - RPS: {workload['rps']} (ì´ˆë‹¹ ìš”ì²­ ìˆ˜)")
    print(f"    - ë™ì‹œì„±: {workload['concurrency']}")
    print(f"    - ì˜ˆìƒ ì´ ìš”ì²­: {workload['duration'] * workload['rps']}ê°œ")
    print(f"    - ìµœëŒ€ í† í°: {workload['max_tokens']}")
    print(f"    - Temperature: {workload['temperature']}")
    print(f"    - í”„ë¡¬í”„íŠ¸ íƒ€ì…: {workload['prompt_type']}")
    print("="*60)
    
    confirm = input("\nì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n) [ê¸°ë³¸ê°’: Y]: ").strip().lower()
    if confirm and confirm != 'y':
        print("\nâŒ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    print("\nğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘!\n")
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark = LLMBenchmark(config_dir, output_dir)
    
    await benchmark.run_workload(
        target,
        model_info['full_name'],
        workload,
        prompts
    )
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"bench_{target['name']}_{model_info['name']}_{workload['name']}_{timestamp}.jsonl"
    benchmark.save_results(output_file)
    
    print("\nâœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
    print(f"\nğŸ“Š ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”:")
    print(f"  python3 scripts/parse_metrics.py {output_file}")
    print(f"  python3 scripts/gen_report.py")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
