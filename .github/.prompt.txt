# LLM Benchmark 프로젝트 지시사항

## 프로젝트 개요
- **프로젝트명**: llm-benchmark
- **목적**: GPU 서버 환경에서 LLM 성능 자동 측정 벤치마크 도구
- **대상**: vLLM, LiteLLM 등 OpenAI 호환 API
- **기술 스택**: Python 3.11+, httpx, asyncio, pyyaml, pandas

## 프로젝트 구조
```
llm-benchmark/
├── scripts/          # 실행 스크립트
│   ├── run_bench.py      # 비동기 부하 테스트
│   ├── parse_metrics.py  # 결과 파싱
│   ├── gen_report.py     # 리포트 생성
│   └── run_bench.sh      # 파이프라인 실행
├── configs/          # 설정 파일 (YAML)
│   ├── targets.yaml      # 엔드포인트
│   ├── models.yaml       # 모델 목록
│   └── workloads.yaml    # 워크로드 패턴
├── results/          # 결과 저장
│   ├── raw/              # JSONL
│   ├── summary/          # CSV
│   └── reports/          # Markdown
└── .github/          # 프로젝트 문서
```

## 측정 지표
- TTFT (Time To First Token): 첫 토큰 지연시간
- 총 응답시간: 요청~응답 완료
- 토큰 처리량: tokens/sec
- 성공률: 안정성 지표

## 서버 접속 정보
**LLM 서버 엔드포인트 및 API 키는 `.github/config.yaml` 참고**

사용 가능한 서버:
- **Titan** (172.21.113.213:4000): Qwen3-4B-Instruct (테스트용)
- **Spark** (172.21.113.31:4000): Qwen3-Coder-30B-A3B-Instruct (테스트용)
- **S-Core** (172.21.135.113:4000): Qwen3-Coder-30B-A3B-Instruct (주력 서버, H200 8장)

벤치마크 설정 시 `configs/targets.yaml`에 위 정보를 반영하여 사용

## 코드 품질 관리

### 문법 오류 확인 및 수정
**코드 변경 후 반드시 `get_errors` 도구로 문법 오류 확인:**
- Python 스크립트 수정 시 `get_errors` 도구 사용
- 발견된 오류는 즉시 수정
- import 누락, 타입 불일치 등 모든 오류 해결

**예시:**
```
1. 코드 수정 완료
2. get_errors 실행하여 에러 확인
3. 에러 발견 시 즉시 수정
4. 다시 get_errors로 검증
5. 에러 없을 때까지 반복
```

## 개발 원칙
- Python PEP 8 스타일 준수
- 함수/클래스에 독스트링 작성
- 타입 힌트 사용
- 비동기 프로그래밍 (async/await)
- YAML 기반 설정 관리

## 벤치마크 작업 완료 시 보고서 작성 (중요!)

**벤치마크 테스트가 완료되면 반드시 완료 보고서를 작성합니다.**

### 보고서 작성 절차

1. **벤치마크 실행 완료 확인**
   - `results/raw/*.jsonl` 파일 생성 확인
   - `results/summary/*.csv` 파일 생성 확인
   - `results/reports/benchmark_report.md` 생성 확인

2. **완료 보고서 작성** (`.github/benchmark-results/YYYYMMDD-HHMMSS-report.md`)
   
   **보고서 포함 내용:**
   - 테스트 일시 및 환경 (서버, 모델, 워크로드)
   - 핵심 성능 지표 요약
     - TTFT (평균, 중앙값, P95, P99)
     - 총 응답시간 (평균, 중앙값, P95, P99)
     - 토큰 처리량 (평균, 중앙값, P95)
     - 성공률
   - 주요 발견사항 및 분석
   - GPU 활용률 (확인 가능한 경우)
   - 개선 권장사항
   - 원시 데이터 및 상세 리포트 링크

3. **세션 파일 업데이트**
   - 해당 세션의 작업 결과에 벤치마크 보고서 링크 추가

4. **Git 커밋**
   - 보고서 파일을 Git에 커밋 및 푸시

### 보고서 템플릿

```markdown
# 벤치마크 완료 보고서

**일시:** YYYY-MM-DD HH:MM:SS  
**작성자:** [이름]

## 테스트 환경
- **서버:** [서버명]
- **모델:** [모델명]
- **워크로드:** [워크로드명]
- **테스트 기간:** [기간]
- **총 요청 수:** [수]

## 핵심 성능 지표

### TTFT (Time To First Token)
- 평균: X.XXXs
- 중앙값: X.XXXs
- P95: X.XXXs
- P99: X.XXXs

### 토큰 처리량
- 평균: XX.X tokens/s
- 중앙값: XX.X tokens/s
- P95: XX.X tokens/s

### 성공률
- 성공: X / 총 X (XX.X%)

## 주요 발견사항
- [분석 내용]

## 결론 및 권장사항
- [권장사항]

## 상세 결과
- 원시 데이터: `results/raw/[파일명]`
- 통계 요약: `results/summary/[파일명]`
- 자동 리포트: `results/reports/benchmark_report.md`
```

### 무한 루프 근본 해결 완료 ✅
**문제**: "이 프로젝트 분석해줘" → list_files (XML) 실행 → 텍스트 응답 → "[Tool 사용 권장 메시지...]" 무한 반복

**원인**: 
- XML Tool이 `else` 블록 내부에 중첩됨 (2등 시민)
- XML 실행 → 재귀 호출 → 텍스트 응답 → `else` 잘못 진입

**해결** (ClineView.java 라인 282-400):
```java
// Before (잘못된 구조):
if (hasJsonTools) {
    executeJsonTools();
} else {
    if (hasXmlTools) {  // ← 중첩!
        executeXmlTools();
    } else {
        textOnly();
    }
}

// After (올바른 구조):
boolean hasJsonTools = message.has("tool_calls") && ...;
List<XmlToolCall> xmlTools = XmlToolParser.parseXmlTools(content);
boolean hasXmlTools = !xmlTools.isEmpty();

if (hasJsonTools) {
    executeJsonTools();
} else if (hasXmlTools) {  // ← 평탄화!
    executeXmlTools();
} else {
    textOnly();
}
```

**결과**: XML과 JSON을 동등하게 처리, 무한 루프 근본 해결

### 새 채팅 완전 초기화 ✅
**VSCode Cline의 clearTask() 패턴 적용**:
- `httpClient` 재생성으로 이전 세션과 완전 분리
- `toolExecutor` 재생성
- `conversationHistory` 초기화
- 모든 상태 완전 리셋

### Qwen3-Coder-30B 분석 완료
- 회사 표준: Qwen3-Coder-30B (Tool Calling 특화)
- 현재 환경: RTX 4070 Super 12GB VRAM
- 결론: 30B는 17GB+ 필요 → **하드웨어 부족으로 14B 유지**
- XML/JSON 파싱으로 유사한 Tool Calling 기능 구현

## 다음 작업
- Eclipse IDE 통합 테스트 (무한 루프 해결 검증)
- 인사말 Tool 호출 문제 개선 (tool_choice API 검토)
