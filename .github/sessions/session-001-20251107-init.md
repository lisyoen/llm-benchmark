# 세션 session-001-20251107-init

## 세션 정보
**세션 ID:** session-001-20251107-init  
**제목:** 프로젝트 초기 구성  
**일시:** 2025-11-07  
**상태:** 완료

---

## 작업 목적
llm-benchmark 프로젝트의 초기 폴더 구조 및 기본 파일을 구성합니다.

**배경:**
- GPU 서버에서 LLM 성능을 자동 측정하기 위한 벤치마크 도구 개발
- vLLM, LiteLLM 등 OpenAI 호환 API 대상 부하 테스트
- TTFT, 응답시간, 토큰 처리량 등 지표 측정 및 리포트 생성

**목표:**
- project-goal.md에 정의된 폴더 구조(scripts/, configs/, results/) 생성
- 설정 파일 템플릿 작성
- 핵심 스크립트 기본 구조 생성
- 문서 파일(README, requirements 등) 작성

---

## 작업 계획
1. 세션 관리 파일 생성 (session-manager.md, current-session.md)
2. 프로젝트 디렉토리 구조 생성
3. 설정 파일(YAML) 템플릿 작성
4. Python 스크립트 기본 틀 생성
5. 프로젝트 문서 작성
6. Git 커밋 및 동기화

---

## 진행 상황

### 완료된 작업
- [x] Git pull로 최신 상태 확인
- [x] TODO 리스트 생성
- [x] 세션 관리 파일 생성 (session-manager.md, current-session.md)
- [x] 프로젝트 폴더 구조 생성
- [x] 설정 파일 생성
- [x] 핵심 스크립트 생성
- [x] 문서 파일 생성
- [x] 프로젝트 컨텍스트 문서 생성

---

## 생성/수정된 파일

### 세션 관리 파일
- `.github/session-manager.md`
- `.github/current-session.md`
- `.github/sessions/session-001-20251107-init.md`
- `.github/project-context.md`
- `.github/work-history.md`

### 프로젝트 구조
- `scripts/run_bench.py` - 비동기 부하 테스트 실행 스크립트
- `scripts/parse_metrics.py` - 결과 파싱 및 통계 계산 스크립트
- `scripts/gen_report.py` - Markdown 리포트 생성 스크립트
- `scripts/run_bench.sh` - 전체 파이프라인 실행 셸 스크립트
- `configs/targets.yaml` - 벤치마크 대상 엔드포인트 설정
- `configs/models.yaml` - 테스트 모델 목록 설정
- `configs/workloads.yaml` - 워크로드 패턴 정의 (RPS, 동시성 등)
- `results/README.md` - results 디렉토리 설명

### 문서
- `README.md` - 프로젝트 사용 가이드 (설치, 사용법, 지표 설명)
- `requirements.txt` - Python 의존성 (httpx, pyyaml, pandas)

---

## 주요 결정사항

### 1. 비동기 부하 테스트 구조
- **httpx**를 사용한 비동기 HTTP 요청 처리
- asyncio 기반으로 대규모 동시 요청 처리
- Streaming API로 TTFT (Time To First Token) 정확히 측정

### 2. 설정 관리
- YAML 형식으로 targets, models, workloads 분리
- 환경변수 지원 (`${OPENAI_API_KEY}`)
- 프롬프트 템플릿을 타입별로 관리 (short, medium, long)

### 3. 데이터 파이프라인
- JSONL (원시 데이터) → CSV (통계) → Markdown (리포트)
- 각 단계별 독립적인 스크립트로 구성
- 재실행 및 재분석 가능한 구조

### 4. 워크로드 시나리오
- low-load, medium-load, high-load, stress-test 4가지 제공
- RPS(초당 요청 수)와 동시성(concurrency)으로 부하 조절
- 실제 사용 패턴을 반영한 프롬프트 템플릿 제공

### 5. 측정 지표
- TTFT, 총 응답시간, 토큰 처리량, 성공률
- 평균, 중앙값, P95, P99 통계 제공
- 향후 GPU 메트릭 통합 확장 가능

---

## 학습한 내용

### 1. LLM 벤치마크 핵심 지표
- **TTFT (Time To First Token)**: 사용자 체감 반응 속도의 핵심 지표
- **토큰 처리량**: 시스템 처리 능력의 지표
- **P95/P99**: 평균보다 안정성을 보여주는 중요한 백분위수

### 2. 비동기 부하 생성
- RPS 유지를 위한 `asyncio.sleep()` 조절
- 동시성 제어를 위한 세마포어 패턴 (향후 적용 가능)
- Streaming 응답 처리 시 첫 토큰 시점 정확히 측정

### 3. 워크로드 설계
- 실제 프로덕션 환경을 반영한 시나리오 필요
- 다양한 프롬프트 길이로 다양한 부하 패턴 테스트
- 점진적 부하 증가로 시스템 한계 파악

---

## 다음 단계

### 즉시 수행
- [ ] Python 의존성 설치 테스트 (`pip install -r requirements.txt`)
- [ ] vLLM 또는 LiteLLM 서버 설정 및 실행
- [ ] 간단한 벤치마크 실행으로 동작 검증

### 확장 기능
- [ ] Prometheus/Grafana 연동으로 GPU 메트릭 수집
- [ ] 토큰당 전력 효율(Tokens/W) 계산
- [ ] HTML 리포트 생성
- [ ] CI/CD 파이프라인 자동화 (GitHub Actions)
