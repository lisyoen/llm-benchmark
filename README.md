# llm-benchmark

GPU ì„œë²„ í™˜ê²½ì—ì„œ LLM ì„±ëŠ¥ì„ ìë™ ì¸¡ì •í•˜ê¸° ìœ„í•œ ë‚´ë¶€ìš© ë²¤ì¹˜ë§ˆí¬ ë„êµ¬ì…ë‹ˆë‹¤.

## ê°œìš”

`llm-benchmark`ëŠ” S-COREì˜ LLM Run Package êµ¬ì„± ìš”ì†Œ(vLLM, LiteLLM ë“±)ë¥¼ ëŒ€ìƒìœ¼ë¡œ  
**ì§€ì—°ì‹œê°„, ì²˜ë¦¬ëŸ‰, ì•ˆì •ì„±, íš¨ìœ¨ì„±**ì„ ìë™ ì¸¡ì •í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

- âœ… OpenAI í˜¸í™˜ API ëŒ€ìƒ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (`/v1/chat/completions`)
- âœ… TTFT (Time To First Token), ì‘ë‹µì‹œê°„, í† í° ì²˜ë¦¬ëŸ‰ ì¸¡ì •
- âœ… ì›Œí¬ë¡œë“œë³„/ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸ ìë™ ìƒì„±
- âœ… ë¹„ë™ê¸° ìš”ì²­ ì²˜ë¦¬ë¡œ ëŒ€ê·œëª¨ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜
- ğŸ”„ GPU ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ ë¶„ì„ (í™•ì¥ ì˜ˆì •)

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
llm-benchmark/
â”œâ”€â”€ scripts/              # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ run_bench.py      # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
â”‚   â”œâ”€â”€ parse_metrics.py  # ê²°ê³¼ íŒŒì‹± ë° í†µê³„ ê³„ì‚°
â”‚   â”œâ”€â”€ gen_report.py     # ë¦¬í¬íŠ¸ ìƒì„±
â”‚   â””â”€â”€ run_bench.sh      # ì „ì²´ íŒŒì´í”„ë¼ì¸ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ configs/              # ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ targets.yaml      # ë²¤ì¹˜ë§ˆí¬ ëŒ€ìƒ ì—”ë“œí¬ì¸íŠ¸
â”‚   â”œâ”€â”€ models.yaml       # í…ŒìŠ¤íŠ¸ ëª¨ë¸ ëª©ë¡
â”‚   â””â”€â”€ workloads.yaml    # ì›Œí¬ë¡œë“œ íŒ¨í„´ ì •ì˜
â”œâ”€â”€ results/              # ê²°ê³¼ ì €ì¥
â”‚   â”œâ”€â”€ raw/              # ì›ì‹œ ì¸¡ì • ë¡œê·¸ (JSONL)
â”‚   â”œâ”€â”€ summary/          # í†µê³„ ìš”ì•½ (CSV)
â”‚   â””â”€â”€ reports/          # ìµœì¢… ë¦¬í¬íŠ¸ (Markdown)
â””â”€â”€ .github/              # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

## ì„¤ì¹˜

### ìš”êµ¬ì‚¬í•­

- Python 3.11+
- pip

### ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

## ì‚¬ìš©ë²•

### 1. ì„¤ì • íŒŒì¼ í¸ì§‘

**ëŒ€ìƒ ì„œë²„ ì„¤ì •** (`configs/targets.yaml`):
```yaml
targets:
  - name: vllm-local
    base_url: http://localhost:8000/v1
    api_key: "EMPTY"
```

**í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì„¤ì •** (`configs/models.yaml`):
```yaml
models:
  - name: llama-3.1-8b-instruct
    full_name: meta-llama/Meta-Llama-3.1-8B-Instruct
```

**ì›Œí¬ë¡œë“œ ì„¤ì •** (`configs/workloads.yaml`):
```yaml
workloads:
  - name: medium-load
    duration: 300  # ì´ˆ
    rps: 5         # Requests Per Second
    concurrency: 10
```

### 2. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

#### ê°œë³„ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python3 scripts/run_bench.py --target vllm-local --model llama-3.1-8b-instruct --workload medium-load

# ê²°ê³¼ íŒŒì‹±
python3 scripts/parse_metrics.py results/raw/bench_*.jsonl

# ë¦¬í¬íŠ¸ ìƒì„±
python3 scripts/gen_report.py
```

#### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
./scripts/run_bench.sh

# íŒŒë¼ë¯¸í„° ì§€ì •
./scripts/run_bench.sh vllm-local llama-3.1-8b-instruct high-load
```

### 3. ê²°ê³¼ í™•ì¸

- **ì›ì‹œ ë°ì´í„°**: `results/raw/*.jsonl`
- **í†µê³„ ìš”ì•½**: `results/summary/*.csv`
- **ë¦¬í¬íŠ¸**: `results/reports/benchmark_report.md`

## ì¸¡ì • ì§€í‘œ

### 1. TTFT (Time To First Token)
ì²« ë²ˆì§¸ í† í°ì´ ìƒì„±ë  ë•Œê¹Œì§€ì˜ ì§€ì—°ì‹œê°„

- Mean, Median, P95, P99

### 2. ì´ ì‘ë‹µ ì‹œê°„
ìš”ì²­ë¶€í„° ì‘ë‹µ ì™„ë£Œê¹Œì§€ì˜ ì´ ì‹œê°„

- Mean, Median, P95, P99

### 3. í† í° ì²˜ë¦¬ëŸ‰
ì´ˆë‹¹ ìƒì„±ë˜ëŠ” í† í° ìˆ˜ (tokens/sec)

- Mean, Median, P95

### 4. ì„±ê³µë¥ 
ì „ì²´ ìš”ì²­ ì¤‘ ì„±ê³µí•œ ìš”ì²­ì˜ ë¹„ìœ¨ (%)

## ì›Œí¬ë¡œë“œ ì‹œë‚˜ë¦¬ì˜¤

| ì‹œë‚˜ë¦¬ì˜¤ | RPS | ë™ì‹œì„± | ì„¤ëª… |
|---------|-----|--------|------|
| `low-load` | 1 | 1 | ê°œë³„ ì‚¬ìš©ì íƒìƒ‰ |
| `medium-load` | 5 | 10 | ì¼ë°˜ì ì¸ í”„ë¡œë•ì…˜ |
| `high-load` | 20 | 50 | í”¼í¬ íƒ€ì„ íŠ¸ë˜í”½ |
| `stress-test` | 50 | 100 | ì‹œìŠ¤í…œ í•œê³„ ì¸¡ì • |

## í™•ì¥ ê³„íš

- [ ] Prometheus/Grafana ì—°ë™ìœ¼ë¡œ GPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] í† í°ë‹¹ ì „ë ¥ íš¨ìœ¨(Tokens/W) ê³„ì‚°
- [ ] ì—¬ëŸ¬ ëª¨ë¸ ê°„ ë¹„êµ ì‹œê°í™”
- [ ] CI íŒŒì´í”„ë¼ì¸ ìë™í™” (GitHub Actions)
- [ ] HTML/PDF ë¦¬í¬íŠ¸ ìƒì„±

## ê°œë°œì ì •ë³´

**ì‘ì„±ì:** ì´ì°½ì—° (AIì‚¬ì—…ê·¸ë£¹)  
**ì‘ì„±ì¼:** 2025-11-07  
**ë¼ì´ì„ ìŠ¤:** MIT

## ê¸°ì—¬

ì´ìŠˆ ë° í’€ ë¦¬í€˜ìŠ¤íŠ¸ í™˜ì˜í•©ë‹ˆë‹¤!

---

**Note:** ì´ ë„êµ¬ëŠ” S-CORE ë‚´ë¶€ ì‚¬ìš©ì„ ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.
